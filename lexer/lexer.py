from grammar import Grammar


def regex_tokenizer(text,G: Grammar):
    tokens = []
    fixed_tokens = 

